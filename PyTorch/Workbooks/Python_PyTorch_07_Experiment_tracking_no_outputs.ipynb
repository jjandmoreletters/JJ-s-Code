{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 07 PyTorch Experiment Tracking\n",
        "\n",
        "Machine learning is very experimental.\n",
        "\n",
        "In order to figure out which experiments are worth pursuing; **experiment tracking** comes in, it helps you to figure out what doesn't work\n",
        "\n",
        "In this norebook, we're going to see an example of programmatically tracking experiments\n",
        "\n",
        "Resources:  \n",
        "- https://www.learnpytorch.io/07_pytorch_experiment_tracking/\n",
        "- Extra: https://madewithml.com/courses/mlops/experiment-tracking/\n"
      ],
      "metadata": {
        "id": "ox1y7dN2y8C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "4l0eYIKBzsPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "FdPtrO9szsKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setup device agnositic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "BEIR0uVpzsCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "1qQRAsNDzr6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting the data\n",
        "\n",
        "Want to get the pizza, steak and sushi images.\n",
        "\n",
        "So we can run experiments building FoodVision Mini and see which model performs best.\n"
      ],
      "metadata": {
        "id": "O7s0A5M61W04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "def download_data(source: str, destination: str,\n",
        "                  remove_source: bool=True)->Path:\n",
        "    \"\"\"Downloads a zipfile from a url and stores it locally\"\"\"\n",
        "    #Set up path to data folder\n",
        "    #source: https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\n",
        "    data_path=Path(\"data/\")\n",
        "    image_path=data_path/destination\n",
        "    # If the image path doesn't exist, download it\n",
        "    if image_path.is_file():\n",
        "      print(f\"[INFO] {image_path} directory already exists, skipping download\")\n",
        "\n",
        "    else:\n",
        "      image_path.mkdir(parents=True, exist_ok=True)\n",
        "      # Download the data\n",
        "      target_file=Path(source).name\n",
        "      with open(data_path/target_file, \"wb\") as f:\n",
        "        request=requests.get(source)\n",
        "        print(f\"[INFO] Downloading {target_file} to {source}...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "      with zipfile.ZipFile(data_path/target_file, \"r\") as zip_ref:\n",
        "        print(f\"[INFO] Extracting {target_file}...\")\n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "      #remove zipfile if needed\n",
        "      if remove_source:\n",
        "        os.remove(data_path/target_file)\n",
        "\n",
        "    return image_path\n",
        "\n"
      ],
      "metadata": {
        "id": "UNh8_3vy1y2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path=download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                        destination=\"pizza_steak_sushi\")"
      ],
      "metadata": {
        "id": "06GYaVJD1yxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Create DataLoaders with manual transforms\n",
        "The goal with transforms is to ensure your custom data is formatted in a reproducible way as well as a way that will be used by your model."
      ],
      "metadata": {
        "id": "y20cviVs4a0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create train_dir, test_dir\n",
        "train_dir=image_path/\"train\"\n",
        "test_dir=image_path/\"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "sfE1ApbY4x8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup ImageNet normalization levels\n",
        "#see 06 notebook for explanation on normalization\n",
        "normalize=transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "manual_transform=transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "print (f\"manually created transforms: {manual_transform}\")\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "hv12eErD5L7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Create Dataloaders using automatically created transforms\n",
        "\n",
        "The same principle applies for automatic transforms: we want our custom data in the same format as a pretrained model was trained on."
      ],
      "metadata": {
        "id": "VBjBh5Bb6N76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#get a set of pretrained model weights (plenty of these weights are available in torchvision.models)\n",
        "weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT #DEFAULT = best available weights\n",
        "weights\n",
        "\n",
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms=weights.transforms()\n",
        "auto_transforms\n",
        "\n",
        "print (f\"automatically created transforms: {auto_transforms}\")\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=auto_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "a0qd7Ca91yur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Getting a pretrained model, freeze base layers and change classifier head"
      ],
      "metadata": {
        "id": "tkCl3-zX7gEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model=torchvision.models.efficientnet_b0(weights=weights)\n",
        "model"
      ],
      "metadata": {
        "id": "geCc6cI07tvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print with torchinfo\n",
        "from torchinfo import summary\n",
        "summary(model, input_size=(1,3,224,224), #example of [batch_size, color_channels, height, width]\n",
        "        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "d9m1GaG47tom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.features.parameters():\n",
        "    #print(param)\n",
        "    param.requires_grad=False"
      ],
      "metadata": {
        "id": "zE2ZabQ07thN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update classifier head of our model to suit our problem\n",
        "from torch import nn\n",
        "\n",
        "set_seeds()\n",
        "\n",
        "#Dropout - https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
        "model.classifier=nn.Sequential(\n",
        "    nn.Dropout(p=0.3), #see data scient cheatsheet for visual display of dropout\n",
        "    nn.Linear(in_features=1280, #feature vector coming in\n",
        "              out_features=len(class_names))).to(device) #how many classes do we have\n",
        "\n",
        "model.classifier"
      ],
      "metadata": {
        "id": "I5b5qAIM7tbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train a single model and track results\n",
        "\n",
        "to track experiments, were using TensorBoard: https://www.tensorflow.org/tensorboard\n",
        "\n",
        "And to interact with TensorBoard, we can sue SummaryWriter: https://pytorch.org/docs/stable/tensorboard.html\n"
      ],
      "metadata": {
        "id": "vb55lYpW7tUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function and optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(params=model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "L94PwL_8NQor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up summarywriter:-https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer=SummaryWriter()"
      ],
      "metadata": {
        "id": "ib0RB_bSNQlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular.engine import train_step, test_step\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "#take train step from engine.py #need to update so it uses a summary writer\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "              train_acc: [...],\n",
        "              test_loss: [...],\n",
        "              test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "             {train_loss: [2.0616, 1.0537],\n",
        "              train_acc: [0.3945, 0.3945],\n",
        "              test_loss: [1.2641, 1.5706],\n",
        "              test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Make sure model on target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        ## New: experiment tracking##\n",
        "        writer.add_scalars(main_tag=\"Loss\",\n",
        "                           tag_scalar_dict={\"train_loss\":train_loss,\n",
        "                                           \"test_loss\":test_loss},\n",
        "                           global_step=epoch)\n",
        "        writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                           tag_scalar_dict={\"train_acc\":train_acc,\n",
        "                                           \"test_acc\":test_acc},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        writer.add_graph(model=model,\n",
        "                         input_to_model=torch.zeros((1, 3, 224, 224)).to(device))\n",
        "\n",
        "        #close the writer\n",
        "        writer.close()\n",
        "        ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "oCwfsvRVNQib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#note: not using engine.py since we've updated the train function\n",
        "set_seeds()\n",
        "train_results=train(model=model,\n",
        "                   train_dataloader=train_dataloader,\n",
        "                   test_dataloader=test_dataloader,\n",
        "                   optimizer=optimizer,\n",
        "                   loss_fn=loss_fn,\n",
        "                   epochs=5,\n",
        "                   device=device)\n",
        "\n",
        "train_results"
      ],
      "metadata": {
        "id": "hebnXF6tNUgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. View our model's results with TensorBoard\n",
        "\n",
        "There are a few ways to view TensorBoard results: https://www.learnpytorch.io/07_pytorch_experiment_tracking/#5-view-our-models-results-in-tensorboard"
      ],
      "metadata": {
        "id": "QzDLWOYXNUcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's view our experiments within the notebook\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "-MtDLgt_NUWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Create a function to prepare a `SummaryWriter()` instance\n",
        "\n",
        "By default our `SummaryWriter()` class saves to `log_dir`\n",
        "\n",
        "How about if we wanted to save different experiemtns to different folders?\n",
        "\n",
        "In sessence, one experiments  means one folder.\n",
        "\n",
        "For example we'd like to track:\n",
        "* Exeperiment date/timestamp\n",
        "* Experiment name\n",
        "* Model name\n",
        "* Extra - is there anything else that should be tracked?\n",
        "\n",
        "Let's create a function to create a `SummaryWriter()` instance to take all of these things into account.\n",
        "\n",
        "So ideally we end up tracking experiments to a directory:\n",
        "\n",
        "`runs/YYYY-MM-DD/experiment_name/model_name/extra`"
      ],
      "metadata": {
        "id": "KDQmE1NHTr89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def create_writer(experiment_name: str,\n",
        "                  model_name: str,\n",
        "                  extra: str =None):\n",
        "\n",
        "  \"creates a torch.utils.tensorboard.SummaryWriter() instance tracking to specific\"\n",
        "\n",
        "  from datetime import datetime\n",
        "  import os\n",
        "\n",
        "  #get timestamp of current date in reverse order\n",
        "  timestamp=datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  if extra:\n",
        "    #create log directory path\n",
        "    log_dir=os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
        "  else:\n",
        "    log_dir=os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "  print(f\"[INFO] Created SummaryWriter saving to {log_dir}\")\n",
        "\n",
        "  return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "VKQu7GTiTr6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_writer=create_writer(experiment_name=\"data_10_percent\",\n",
        "                           model_name=\"effnet_b0\",\n",
        "                           extra=\"5_epochs\")"
      ],
      "metadata": {
        "id": "B7tbTH2MTr1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Update the `train()` function to include `writer` parameter"
      ],
      "metadata": {
        "id": "k1NTl6Jdi_xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#update train() to use create_writer...\n",
        "\n",
        "from going_modular.going_modular.engine import train_step, test_step\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "#take train step from engine.py #need to update so it uses a summary writer\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          writer: torch.utils.tensorboard.writer.SummaryWriter) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "              train_acc: [...],\n",
        "              test_loss: [...],\n",
        "              test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "             {train_loss: [2.0616, 1.0537],\n",
        "              train_acc: [0.3945, 0.3945],\n",
        "              test_loss: [1.2641, 1.5706],\n",
        "              test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Make sure model on target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        ## New: experiment tracking##\n",
        "        if writer:\n",
        "          writer.add_scalars(main_tag=\"Loss\",\n",
        "                            tag_scalar_dict={\"train_loss\":train_loss,\n",
        "                                            \"test_loss\":test_loss},\n",
        "                            global_step=epoch)\n",
        "          writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                            tag_scalar_dict={\"train_acc\":train_acc,\n",
        "                                            \"test_acc\":test_acc},\n",
        "                            global_step=epoch)\n",
        "\n",
        "          writer.add_graph(model=model,\n",
        "                          input_to_model=torch.zeros((1, 3, 224, 224)).to(device))\n",
        "\n",
        "          #close the writer\n",
        "          writer.close()\n",
        "        else:\n",
        "          pass\n",
        "          ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "CT_xgx5_Try9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Setting up a series of modelling experiments\n",
        "\n",
        "* Setup 2x modelling experiments with pizza, steak, sushi data and train one model for 5 epochs and another model for 10 epochs."
      ],
      "metadata": {
        "id": "a0axfGqiTrwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=[5,10]\n",
        "set_seeds()\n",
        "for epoch in epochs:\n",
        "  print(f\"training model for {epoch} epochs\")\n",
        "  #train model\n",
        "  #note: not using engine.py since we've updated the train function\n",
        "  epoch_writer=create_writer(experiment_name=f\"data_at_{epoch}_epochs\",\n",
        "                model_name=\"effnet_b0\",\n",
        "                extra=f\"{epoch}_epochs\")\n",
        "\n",
        "  train_results=train(model=model,\n",
        "                    train_dataloader=train_dataloader,\n",
        "                    test_dataloader=test_dataloader,\n",
        "                    optimizer=optimizer,\n",
        "                    loss_fn=loss_fn,\n",
        "                    epochs=epoch, #whoops forgot to change epoch hyperparam first time round\n",
        "                    device=device,\n",
        "                    writer=epoch_writer)\n",
        "\n",
        "  print(f\"{epoch} epochs complete\")"
      ],
      "metadata": {
        "id": "1qruR2L7TrsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 What kind of experiments should you run?\n",
        "\n",
        "The number of ML experiments you can run is like the number of models you can build...almost limitless.\n",
        "\n",
        "However, you can't test everything...\n",
        "\n",
        "So what do we test?\n",
        "* Change the number of epochs\n",
        "* Change the number of hidden layers/units\n",
        "* Change the amount of data (right now we're using 10% of the food 101 dataset for Pizza steak and sushi)\n",
        "* Change learning rate\n",
        "* Change optimizer\n",
        "* Change different model architecture\n",
        "* Try different data augmentation\n",
        "\n",
        "This is why transfer learning is so powerful, it's a working model that you can apply to your own work                                                                                       "
      ],
      "metadata": {
        "id": "U_9yFvWpTrps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 What experiment are we going to run?\n",
        "\n",
        "We're looking to turn three dials:\n",
        "1. Model size - EffnetB0 vs EffnetB2 (in terms of number of params)\n",
        "2. Datasetsize - 10% of PSS images vs 20% (generally more data=better results)\n",
        "3. Training time - 5epochs vs 10 epochs (generally longer training time=better results, up to a point)\n",
        "\n",
        "To begin we're keeping things relatively small so our experiments run quickly\n",
        "\n",
        "Our goal: a model that is well performing but still small enough to run on a mobile device or web browser, so FoodVisionMini can come to life.\n",
        "\n",
        "If you had infinite compute + time you should basically always choose the biggest model and biggest dataset you can.\n",
        "\n",
        "Seee:\n",
        "http://www.incompleteideas.net/IncIdeas/BitterLesson.html"
      ],
      "metadata": {
        "id": "4QSrMc2UNUSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Download different datasets\n",
        "\n",
        "We want two datasets:\n",
        "\n",
        "1. 10% of pizza, steak, sushi: https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\n",
        "2. 20% of pizza, steak, sushi: https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\n",
        "\n",
        "They were created with: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/04_pytorch_custom_datasets.ipynb"
      ],
      "metadata": {
        "id": "TTkULhLXNUNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download 10% and 20% data\n",
        "data_10_percent_path=download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                                   destination=\"pizza_steak_sushi\")\n",
        "\n",
        "data_20_percent_path=download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
        "                                   destination=\"pizza_steak_sushi_20_percent\")"
      ],
      "metadata": {
        "id": "gB-zvr8W7hT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Transform Datasets and Create DataLoaders\n",
        "\n",
        "We'll need to transform our data in a few ways:\n",
        "\n",
        "1. Resize the images to (224,224)\n",
        "2. Make sure image tensor values are between [0,1]\n",
        "3. Normalize the images so they have the same data distribution as ImageNet\n",
        "\n",
        "when using pretrained models/transfer learning, musttransform data same as what model was trained on."
      ],
      "metadata": {
        "id": "MhOnHINE7hQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup training directory paths\n",
        "train_dir_10_percent=data_10_percent_path/\"train\"\n",
        "train_dir_20_percent=data_20_percent_path/\"train\"\n",
        "\n",
        "#set up test directory\n",
        "test_dir=data_10_percent_path/\"test\"\n",
        "\n",
        "train_dir_10_percent, train_dir_20_percent, test_dir"
      ],
      "metadata": {
        "id": "KQzsaJAe7hLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "#setup Imagenet normalization levels\n",
        "#see here: https://pytorch.org/vision/0.12/models.html\n",
        "normalize=torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                            std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "#compose transform\n",
        "simple_transform=transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])"
      ],
      "metadata": {
        "id": "-p0tP0nz8Mx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=32\n",
        "\n",
        "from going_modular.going_modular.data_setup import create_dataloaders\n",
        "\n",
        "#CREATE 10% TRAINING AND TEST dATAlOADERS\n",
        "\n",
        "train_dataloader_10_percent, test_dataloader, class_names = create_dataloaders(\n",
        "    train_dir=train_dir_10_percent,\n",
        "    test_dir=test_dir,\n",
        "    transform=simple_transform,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "train_dataloader_20_percent, test_dataloader, class_names = create_dataloaders(\n",
        "    train_dir=train_dir_20_percent,\n",
        "    test_dir=test_dir,\n",
        "    transform=simple_transform,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "print(f\"number of batches of size {BATCH_SIZE} in training dataloader 10% percent: {len(train_dataloader_10_percent)}\")\n",
        "print(f\"number of batches of size {BATCH_SIZE} in test dataloader 10% percent: {len(test_dataloader)}\")\n",
        "print(f\"number of batches of size {BATCH_SIZE} in training dataloader 20% percent: {len(train_dataloader_20_percent)}\")"
      ],
      "metadata": {
        "id": "33FA2Cmf7hI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 Create feature extraction models\n",
        "\n",
        "We want two functions:\n",
        "1. Create a `torchvision.models.efficientnet_b0()` feature extractor with a frozen backbone/base layers and a custom classifier head (EffNetB0)\n",
        "2. Create a `torchvision.models.efficientnet_b2()` feature extractor with a frozen backbone/base layers and a custom classifier head (EffNetB2)"
      ],
      "metadata": {
        "id": "NuxdIr-l7hGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "#create an EffNetB2\n",
        "effnetb2_weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "effnetb2=torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
        "effnetb2"
      ],
      "metadata": {
        "id": "N5NqF4CKA1V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print with torchinfo\n",
        "from torchinfo import summary\n",
        "summary(effnetb2, input_size=(1,3,224,224), #example of [batch_size, color_channels, height, width]\n",
        "        col_names=[\"input_size\",\"output_size\",\"num_params\",\"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "r-vEVAUuBOw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "OUT_FEATURES=len(class_names)\n",
        "\n",
        "#create an EffNetB0 feature extractor\n",
        "\n",
        "def create_effnetb0():\n",
        "  #get weights and setup a model\n",
        "  weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "  model=torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "  #freeze base layers\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "  #change classifier head\n",
        "  set_seeds()\n",
        "  model.classifier=nn.Sequential(\n",
        "      nn.Dropout(p=0.2),\n",
        "      nn.Linear(in_features=1280,\n",
        "                out_features=OUT_FEATURES).to(device)\n",
        "  )\n",
        "\n",
        "  #give model name\n",
        "  model.name=\"effnetb0\"\n",
        "  print(f\"[INFO] Create {model.name} model...\")\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "pygIKsqmA1SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "created_model_test=create_effnetb0()"
      ],
      "metadata": {
        "id": "Qs-3eEboA1Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "OUT_FEATURES=len(class_names)\n",
        "\n",
        "#create an EffNetB0 feature extractor\n",
        "\n",
        "def create_effnetb2():\n",
        "  #get weights and setup a model\n",
        "  weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  model=torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
        "\n",
        "  #freeze base layers\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "  #change classifier head\n",
        "  set_seeds()\n",
        "  model.classifier=nn.Sequential(\n",
        "      nn.Dropout(p=0.3),\n",
        "      nn.Linear(in_features=1408,\n",
        "                out_features=OUT_FEATURES).to(device)\n",
        "  )\n",
        "\n",
        "  #give model name\n",
        "  model.name=\"effnetb2\"\n",
        "  print(f\"[INFO] Create {model.name} model...\")\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ew_yvg7TA1ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "created_model_test_effnetb2=create_effnetb2()"
      ],
      "metadata": {
        "id": "XadUSmFeA1Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.6 Create experiments and set up training code"
      ],
      "metadata": {
        "id": "vimN6BVRC6FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create epoch list\n",
        "num_epochs=[5,10]\n",
        "\n",
        "#create model list (need to create a new model for each experiment)\n",
        "models=[\"effnetb0\", \"effnetb2\"]\n",
        "\n",
        "#Create a DataLoaders dictionary\n",
        "train_dataloaders={\n",
        "    \"data_10_percent\":train_dataloader_10_percent,\n",
        "    \"data_20_percent\":train_dataloader_20_percent\n",
        "}"
      ],
      "metadata": {
        "id": "FguHywh0C6Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eeQwwev0KR3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from going_modular.going_modular.utils import save_model\n",
        "\n",
        "#set seeds\n",
        "set_seeds()\n",
        "\n",
        "#keep track of experiment numbers\n",
        "experiment_number=0\n",
        "\n",
        "#loop through each DataLoader\n",
        "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
        "  #loop through the epochs\n",
        "  for epochs in num_epochs:\n",
        "    #loop through each model name and create a new model instance\n",
        "    for model_name in models:\n",
        "\n",
        "      #print out info\n",
        "      experiment_number+=1\n",
        "      print(f\"[INFO] Experiment number: {experiment_number}\")\n",
        "      print(f\"[INFO] Model: {model_name} \")\n",
        "      print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
        "      print(f\"[INFO] Epochs: {epochs}\")\n",
        "\n",
        "\n",
        "      #select and create the model\n",
        "      if model_name==\"effnetb0\":\n",
        "        model=create_effnetb0()\n",
        "      else:\n",
        "        model=create_effnetb2()\n",
        "\n",
        "      #create a new loss and optimizer for every model\n",
        "      loss_fn=torch.nn.CrossEntropyLoss()\n",
        "      optimizer=torch.optim.Adam(params=model.parameters(),\n",
        "                                 lr=0.001)\n",
        "\n",
        "      #Train target model with target dataloader and track experiments\n",
        "      train(model=model,\n",
        "            train_dataloader=train_dataloader,\n",
        "            test_dataloader=test_dataloader,\n",
        "            optimizer=optimizer,\n",
        "            loss_fn=loss_fn,\n",
        "            epochs=epochs,\n",
        "            device=device,\n",
        "            writer=create_writer(experiment_name=dataloader_name,\n",
        "                                 model_name=model_name,\n",
        "                                 extra=f\"{epochs} epochs\"))\n",
        "\n",
        "\n",
        "      #save the model to file so we can import it later\n",
        "\n",
        "      save_filepath=f\"07_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
        "\n",
        "      save_model(model=model,\n",
        "                target_dir=\"models\",\n",
        "                model_name=save_filepath)\n",
        "\n",
        "      print(f\"-\"*50 +\"\\n\")"
      ],
      "metadata": {
        "id": "_ZOm8uXjC6AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. View experiments in TensorBoard\n",
        "\n",
        "We've followed the principle experiment, experiment, experiment...\n",
        "\n",
        "Now let's visualise, visualise, visualise..."
      ],
      "metadata": {
        "id": "5dIBAeUVC59D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's view experiments within TensorBoard from within the notebook\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "ttHqRsdEC56N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best performing model was:\n",
        "* Model: EffNetB2\n",
        "* DataLoader: 20% of pizza, steak, sushi\n",
        "* Epochs: 10\n",
        "\n",
        "And the overall trend of all the results was that more data, bigger model and longer training time generally led to better results."
      ],
      "metadata": {
        "id": "rHdhHUwZC53H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Upload the results to TensorBoard.dev (uncomment to try it out)\n",
        "# !tensorboard dev upload --logdir runs \\\n",
        "#     --name \"07. PyTorch Experiment Tracking: FoodVision Mini model results\" \\\n",
        "#     --description \"Comparing results of different model size, training data amount and training time.\""
      ],
      "metadata": {
        "id": "Jl-gcKUcTWN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Running the cell above results in the experiments from this notebook being publically viewable at: https://tensorboard.dev/experiment/VySxUYY7Rje0xREYvCvZXA/\n",
        "\n",
        "    Note: Beware that anything you upload to tensorboard.dev is publically available for anyone to see. So if you do upload your experiments, be careful they don't contain sensitive information.\n",
        "\n"
      ],
      "metadata": {
        "id": "dgv15-rRTWHv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C-PwCB0qTWBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Load in the best Model and make predictions with it\n",
        "\n",
        "This is our best model filepath: `models/07_effnetb2_data_20_percent_10_epochs.pth`"
      ],
      "metadata": {
        "id": "lIhijmFfTV6v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "micH3Fj6XEA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the best model filepath\n",
        "best_model_path = \"models/07_effnetb2_data_20_percent_10_epochs.pth\"\n",
        "\n",
        "# Instantiate a new instance of EffNetB2 (to load the saved state_dict() to)\n",
        "best_model = create_effnetb2()\n",
        "\n",
        "# Load the saved best model state_dict()\n",
        "best_model.load_state_dict(torch.load(best_model_path))"
      ],
      "metadata": {
        "id": "XDiMv0JDWb-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to create a FoodVision Mini model that performs well enough and is able to run on a mobile device/web browser."
      ],
      "metadata": {
        "id": "SfWBSWsZXrnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check model file size\n",
        "from pathlib import Path\n",
        "\n",
        "#Get the model size in bytes then convert it to megabytes\n",
        "effnetb2_model_size=Path(best_model_path).stat().st_size//(1024*1024)\n",
        "print(f\"Model size: {effnetb2_model_size} MB\")"
      ],
      "metadata": {
        "id": "RToJLOXrWbyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import function to make predictions on images"
      ],
      "metadata": {
        "id": "YkdsCByzWbrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular.predictions import pred_and_plot_image\n",
        "\n",
        "#get random list of 3 image path names from test dataset\n",
        "import random\n",
        "num_images_to_plot=3\n",
        "random_image_paths=list(Path(data_20_percent_path/\"test\").glob(\"*/*.jpg\"))\n",
        "test_image_path_sample=random.sample(random_image_paths,\n",
        "                                     k=num_images_to_plot)\n",
        "\n",
        "\n",
        "for image_path in test_image_path_sample:\n",
        "  pred_and_plot_image(model=best_model,\n",
        "                      image_path=image_path,\n",
        "                      class_names=class_names,\n",
        "                      image_size=(224,224))"
      ],
      "metadata": {
        "id": "mTIWjcPuY2nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 Predict on a custom image with best model"
      ],
      "metadata": {
        "id": "ggBKTQeNY2gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download custom image\n",
        "import requests\n",
        "\n",
        "# Setup custom image path\n",
        "custom_image_path = Path(\"data/04-pizza-dad.jpeg\")\n",
        "\n",
        "# Download the image if it doesn't already exist\n",
        "if not custom_image_path.is_file():\n",
        "    with open(custom_image_path, \"wb\") as f:\n",
        "        # When downloading from GitHub, need to use the \"raw\" file link\n",
        "        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
        "        print(f\"Downloading {custom_image_path}...\")\n",
        "        f.write(request.content)\n",
        "else:\n",
        "    print(f\"{custom_image_path} already exists, skipping download.\")\n",
        "\n",
        "#predict on our own custom image\n",
        "pred_and_plot_image(model=best_model,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names)"
      ],
      "metadata": {
        "id": "vY-NxvzMY2aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises"
      ],
      "metadata": {
        "id": "e043RDEVaar4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U --pre torch torchvision --extra-index-url https://download.pytorch.org/whl/nightly/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ],
      "metadata": {
        "id": "ruKyUxE5KC5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "lb9yp7TkKCyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(f\"[INFO] Couldn't import torchinfo...installing\")\n",
        "  !pip install torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "# try to import going modular file from github\n",
        "try:\n",
        "  from going_modular import data_setup, engine\n",
        "except:\n",
        "  print(f\"[INFO] Couldn't import going_modular...downloading\")\n",
        "  !git clone https://github.com/jjandmoreletters/JJ-s-Code\n",
        "  !mv JJ-s-Code/going_modular .\n",
        "  !rm -rf JJ-s-Code\n",
        "  from going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "-dQF7N_yKCvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting setup\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# This notebook requires torch v0.12+ and torchvision v0.13+\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "Xf4MIoo-KCst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set seeds\n",
        "def set_seeds(seed:int=77):\n",
        "  \"\"\"Sets random state for torch operations.\n",
        "\n",
        "  Args:\n",
        "    seed (int, optional): Random seed to set. Defaults to 77.\n",
        "  \"\"\"\n",
        "  #sets seed for general operations\n",
        "  torch.manual_seed(seed)\n",
        "  #sets seed for cuda operations\n",
        "  torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "RyhlXGzNKCpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "def download_data(source:str,\n",
        "                  destination:str,\n",
        "                  remove_source:bool=None)->Path:\n",
        "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
        "\n",
        "    Args:\n",
        "        source (str): A link to a zipped file containing data.\n",
        "        destination (str): A target directory to unzip data to.\n",
        "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path to downloaded data.\n",
        "\n",
        "    Example usage:\n",
        "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                      destination=\"pizza_steak_sushi\")\n",
        "    \"\"\"\n",
        "\n",
        "    #setup data pth\n",
        "    data_path=Path(\"data/\")\n",
        "    image_path=data_path/destination\n",
        "\n",
        "    #if image path exists, otherwise create\n",
        "    if image_path.is_dir():\n",
        "        print(f\"{image_path} already exists, skipping download.\")\n",
        "    else:\n",
        "        print(f\"Did not find {image_path}...creating\")\n",
        "        image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    #download PSS data from git\n",
        "    target_file=Path(source).name\n",
        "    with open(data_path/target_file, \"wb\") as f:\n",
        "        request=requests.get(source)\n",
        "        print(f\"Downloading {target_file} from {source}...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    #unzip file\n",
        "    with zipfile.ZipFile(data_path/target_file, \"r\") as zip_ref:\n",
        "        print(f\"Unzipping {target_file}...\")\n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    #remove if specified\n",
        "    if remove_source:\n",
        "        os.remove(data_path/target_file)\n",
        "\n",
        "    return image_path\n",
        "\n",
        "\n",
        "image_path=download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                      destination=\"pizza_steak_sushi\")##remove_source=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "image_path"
      ],
      "metadata": {
        "id": "xHySHKdNKClj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "def create_writer(experiment_name: str,\n",
        "                  model_name: str,\n",
        "                  extra: str=None):\n",
        "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
        "\n",
        "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
        "\n",
        "    Where timestamp is the current date in YYYY-MM-DD format.\n",
        "\n",
        "    Args:\n",
        "        experiment_name (str): Name of experiment.\n",
        "        model_name (str): Name of model.\n",
        "        extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
        "\n",
        "    Example usage:\n",
        "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
        "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
        "                               model_name=\"effnetb2\",\n",
        "                               extra=\"5_epochs\")\n",
        "        # The above is the same as:\n",
        "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "\n",
        "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
        "\n",
        "    if extra:\n",
        "        # Create log directory path\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
        "    else:\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
        "    return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "ouNFDe6HKChL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from typing import List,Dict\n",
        "\n",
        "from going_modular.engine import train_step, test_step\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n",
        "          ) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Stores metrics to specified writer log_dir if present.\n",
        "\n",
        "    Args:\n",
        "      model: A PyTorch model to be trained and tested.\n",
        "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "      epochs: An integer indicating how many epochs to train for.\n",
        "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "      writer: A SummaryWriter() instance to log model results to.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of training and testing loss as well as training and\n",
        "      testing accuracy metrics. Each metric has a value in a list for\n",
        "      each epoch.\n",
        "      In the form: {train_loss: [...],\n",
        "                train_acc: [...],\n",
        "                test_loss: [...],\n",
        "                test_acc: [...]}\n",
        "      For example if training for epochs=2:\n",
        "              {train_loss: [2.0616, 1.0537],\n",
        "                train_acc: [0.3945, 0.3945],\n",
        "                test_loss: [1.2641, 1.5706],\n",
        "                test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    #create empty results dict\n",
        "    results={\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\":[],\n",
        "             \"test_acc\":[]}\n",
        "\n",
        "\n",
        "    #Loop through training and testing steps for number of epochs\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      train_loss, train_acc=train_step(model=model,\n",
        "                                      dataloader=train_dataloader,\n",
        "                                      loss_fn=loss_fn,\n",
        "                                      optimizer=optimizer,\n",
        "                                      device=device)\n",
        "      #test step\n",
        "      test_loss, test_acc=test_step(model=model,\n",
        "                                  dataloader=test_dataloader,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  device=device)\n",
        "      #print out results\n",
        "      print(f\"Epoch: {epoch+1} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "      #append losses and accuracies to dictiopnary\n",
        "      results[\"train_loss\"].append(train_loss)\n",
        "      results[\"train_acc\"].append(train_acc)\n",
        "      results[\"test_loss\"].append(test_loss)\n",
        "      results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "      ### New: Use the writer parameter to track experiments ###\n",
        "      # See if there's a writer, if so, log to it\n",
        "      if writer:\n",
        "          # Add results to SummaryWriter\n",
        "          writer.add_scalars(main_tag=\"Loss\",\n",
        "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                                \"test_loss\": test_loss},\n",
        "                               global_step=epoch)\n",
        "          writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
        "                                                \"test_acc\": test_acc},\n",
        "                               global_step=epoch)\n",
        "\n",
        "            # Close the writer\n",
        "          writer.close()\n",
        "      else:\n",
        "          pass\n",
        "    ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "Rj5QsTOQKSgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download 10 percent and 20 percent training data (if necessary)\n",
        "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                                     destination=\"pizza_steak_sushi\")\n",
        "\n",
        "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
        "                                     destination=\"pizza_steak_sushi_20_percent\")"
      ],
      "metadata": {
        "id": "IUuNwC97KSdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up train directory paths\n",
        "\n",
        "train_dir_10_percent=data_10_percent_path/\"train\"\n",
        "train_dir_20_percent=data_20_percent_path/\"train\"\n",
        "\n",
        "#setup testing directory paths (note: use same test data for both models)\n",
        "test_dir=data_10_percent_path/\"test\"\n",
        "\n",
        "#check the directories\n",
        "print(f\"train_dir_10_percent: {train_dir_10_percent}\")\n",
        "print(f\"train_dir_20_percent: {train_dir_20_percent}\")\n",
        "print(f\"testing directory: {test_dir}\")"
      ],
      "metadata": {
        "id": "MgYdbcMvKSbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Create a transform to normalize data distribution to be inline with ImageNet\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], # values per colour channel [red, green, blue]\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Create a transform pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "                                       transforms.Resize((224, 224)),\n",
        "                                       transforms.ToTensor(), # get image values between 0 & 1\n",
        "                                       normalize\n",
        "])"
      ],
      "metadata": {
        "id": "OR5HPlsjKSYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create 10% training and test DataLoaders\n",
        "train_dataloader_10_percent, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_10_percent,\n",
        "                                                                                          test_dir=test_dir,\n",
        "                                                                                          transform=simple_transform,\n",
        "                                                                                          batch_size=BATCH_SIZE)\n",
        "\n",
        "# Create 20% training and test DataLoaders\n",
        "train_dataloader_20_percent, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
        "                                                                                          test_dir=test_dir,\n",
        "                                                                                          transform=simple_transform,\n",
        "                                                                                          batch_size=BATCH_SIZE)\n",
        "\n",
        "# Find the number of samples/batches per dataloader (using the same test_dataloader for both experiments)\n",
        "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training data: {len(train_dataloader_10_percent)}\")\n",
        "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data: {len(train_dataloader_20_percent)}\")\n",
        "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(train_dataloader_10_percent)} (all experiments will use the same test set)\")\n",
        "print(f\"Number of classes: {len(class_names)}, class names: {class_names}\")"
      ],
      "metadata": {
        "id": "xSJ-i0tBKSUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 1: Pick a larger model from torchvision.models to add to the list of experiments (for example, EffNetB3 or higher)\n",
        "\n",
        "tried out EffNetB0 and EffNetB2 with ~4M parameters and ~9M parameters respectively. Trying a bigger model.\n",
        "\n",
        "EfficientNet_V2_s:https://pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_v2_s.html#torchvision.models.EfficientNet_V2_S_Weights\n",
        "\n",
        "We'll compare EffNEtB2 to EffNetV2_S"
      ],
      "metadata": {
        "id": "PVXtzTBEjl9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "effnetv2_s_weights=models.EfficientNet_V2_S_Weights.DEFAULT #DEFAULT=\"best available weights\"\n",
        "effnetv2_s=models.efficientnet_v2_s(weights=effnetv2_s_weights)\n",
        "effnetv2_s"
      ],
      "metadata": {
        "id": "BjZk_PtSjl1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_effnetv2_s(out_features: int=len(class_names)):\n",
        "  weights=torchvision.models.EfficientNet_V2_S_Weights.DEFAULT #DEFAULT=\"best available weights\"\n",
        "  model=torchvision.models.efficientnet_v2_s(weights=weights).to(device)\n",
        "  dropout=0.2\n",
        "  in_features=1280#model.classifier.in_features\n",
        "\n",
        "  #freeze base layer\n",
        "  for param in model.features.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "  #change classifier head\n",
        "  set_seeds()\n",
        "\n",
        "  #update classifier head\n",
        "  model.classifier=nn.Sequential(nn.Dropout(p=dropout),\n",
        "                                 nn.Linear(in_features=in_features,\n",
        "                                           out_features=out_features)).to(device)\n",
        "\n",
        "  #set model name\n",
        "  model.name=\"effnetv2_s\"\n",
        "  print(f\"Model name: {model.name}\")\n",
        "  return model\n",
        "\n",
        "  #############\n",
        "\n",
        "def create_effnetb2(out_features: int=len(class_names)):\n",
        "  weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT #DEFAULT=\"best available weights\"\n",
        "  model=torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
        "  dropout=0.3\n",
        "  in_features=1408#model.classifier.in_features\n",
        "\n",
        "  #freeze base layer\n",
        "  for param in model.features.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "  #change classifier head\n",
        "  set_seeds()\n",
        "\n",
        "  #update classifier head\n",
        "  model.classifier=nn.Sequential(nn.Dropout(p=dropout),\n",
        "                                 nn.Linear(in_features=in_features,\n",
        "                                           out_features=out_features)).to(device)\n",
        "\n",
        "  #set model name\n",
        "  model.name=\"effnetb2\"\n",
        "  print(f\"Model name: {model.name}\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "YZjxDufYjlsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetv2_s.classifier"
      ],
      "metadata": {
        "id": "JfHtWr2o8I_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "effnetv2_s = create_effnetv2_s()\n",
        "\n",
        "summary(model=effnetv2_s,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "z9-6dQosjljd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### setup modelling experiments\n",
        "\n",
        "same code used in https://www.learnpytorch.io/07_pytorch_experiment_tracking/#76-create-experiments-and-set-up-training-code"
      ],
      "metadata": {
        "id": "SN8HeNmNjpFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create epoch list\n",
        "num_epochs = [5, 10]\n",
        "\n",
        "# Create models list\n",
        "models = [\"effnetb2\", \"effnetv2_s\"]\n",
        "\n",
        "# Create dataloaders dictionary for various dataloaders\n",
        "train_dataloaders = {\"data_10_percent\": train_dataloader_10_percent,\n",
        "                     \"data_20_percent\": train_dataloader_20_percent}"
      ],
      "metadata": {
        "id": "MtrVShBznMjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from going_modular.utils import save_model\n",
        "\n",
        "#set seeds\n",
        "set_seeds()\n",
        "\n",
        "#keep track of experiment numbers\n",
        "experiment_number=0\n",
        "\n",
        "#loop through each DataLoader\n",
        "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
        "  #loop through the epochs\n",
        "  for epochs in num_epochs:\n",
        "    #loop through each model name and create a new model instance\n",
        "    for model_name in models:\n",
        "\n",
        "      #print out info\n",
        "      experiment_number+=1\n",
        "      print(f\"[INFO] Experiment number: {experiment_number}\")\n",
        "      print(f\"[INFO] Model: {model_name} \")\n",
        "      print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
        "      print(f\"[INFO] Epochs: {epochs}\")\n",
        "\n",
        "\n",
        "      #select and create the model\n",
        "      if model_name==\"effnetb2\":\n",
        "        model=create_effnetb2()\n",
        "      else:\n",
        "        model=create_effnetv2_s()\n",
        "\n",
        "      #create a new loss and optimizer for every model\n",
        "      loss_fn=torch.nn.CrossEntropyLoss()\n",
        "      optimizer=torch.optim.Adam(params=model.parameters(),\n",
        "                                 lr=0.001)\n",
        "\n",
        "      #Train target model with target dataloader and track experiments\n",
        "      train(model=model,\n",
        "            train_dataloader=train_dataloader,\n",
        "            test_dataloader=test_dataloader,\n",
        "            optimizer=optimizer,\n",
        "            loss_fn=loss_fn,\n",
        "            epochs=epochs,\n",
        "            device=device,\n",
        "            writer=create_writer(experiment_name=dataloader_name,\n",
        "                                 model_name=model_name,\n",
        "                                 extra=f\"{epochs} epochs\"))\n",
        "\n",
        "\n",
        "      #save the model to file so we can import it later\n",
        "\n",
        "      save_filepath=f\"07_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
        "\n",
        "      save_model(model=model,\n",
        "                target_dir=\"models\",\n",
        "                model_name=save_filepath)\n",
        "\n",
        "      print(f\"-\"*50 +\"\\n\")"
      ],
      "metadata": {
        "id": "ZZ_X6iSCjpCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect model results"
      ],
      "metadata": {
        "id": "rQRCEtX0jo_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "GlLkY9Tijo70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EffNetV2_S with 10 epochs and 20% of the data gets the best performance (lowest test loss and highest test acucracy)."
      ],
      "metadata": {
        "id": "uJIbr9yrna-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2. Introduce data augmentation to the list of experiments using the 20% pizza, steak, sushi training and test datasets, does this change anything?\n",
        "* For example, you could have one training DataLoader that uses data augmentation (e.g. `train_dataloader_20_percent_aug` and `train_dataloader_20_percent_no_aug`) and then compare the results of two of the same model types training on these two DataLoaders.\n",
        "  * **Note**: You may need to alter the `create_dataloaders()` function to be able to take a transform for the training data and the testing data (because you don't need to perform data augmentation on the test data)"
      ],
      "metadata": {
        "id": "h-wcXSFwjo3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transform_data_aug=transforms.Compose([\n",
        "                                       transforms.Resize((224, 224)),\n",
        "                                       transforms.TrivialAugmentWide(),\n",
        "                                       transforms.ToTensor(), # get image values between 0 & 1\n",
        "                                       normalize\n",
        "])\n",
        "\n",
        "no_data_aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])"
      ],
      "metadata": {
        "id": "NmakRnLQnpSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Have to update `create_dataloaders()` to handle different augmentations\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "NUM_WORKERS = os.cpu_count() # use maximum number of CPUs for workers to load data\n",
        "\n",
        "# Note: this is an update version of data_setup.create_dataloaders to handle\n",
        "# differnt train and test transforms.\n",
        "def create_dataloaders(\n",
        "    train_dir,\n",
        "    test_dir,\n",
        "    train_transform, # add parameter for train transform (transforms on train dataset)\n",
        "    test_transform,  # add parameter for test transform (transforms on test dataset)\n",
        "    batch_size=32, num_workers=NUM_WORKERS\n",
        "  ):\n",
        "    \"\"\"Creates training and testing DataLoaders.\n",
        "\n",
        "    Takes in a training directory and testing directory path and turns\n",
        "    them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
        "\n",
        "    Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader.\n",
        "\n",
        "    Returns:\n",
        "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
        "    Where class_names is a list of the target classes.\n",
        "    Example usage:\n",
        "      train_dataloader, test_dataloader, class_names = \\\n",
        "        = create_dataloaders(train_dir=path/to/train_dir,\n",
        "                             test_dir=path/to/test_dir,\n",
        "                             transform=some_transform,\n",
        "                             batch_size=32,\n",
        "                             num_workers=4)\n",
        "    \"\"\"\n",
        "\n",
        "    # Use ImageFolder to create dataset(s)\n",
        "    train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "    test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = train_data.classes\n",
        "\n",
        "    # Turn images into data loaders\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "rqFP1awinpPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test directories\n",
        "train_20_percent_dir = image_path / \"train\"\n",
        "test_20_percent_dir = image_path / \"test\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create train dataloader *with* data augmentation\n",
        "train_dataloader_20_percent_with_aug, test_dataloader_20_percent, class_names = create_dataloaders(train_dir=train_20_percent_dir,\n",
        "                                                                                                   test_dir=test_20_percent_dir,\n",
        "                                                                                                   train_transform=train_transform_data_aug,\n",
        "                                                                                                   test_transform=no_data_aug_transform,\n",
        "                                                                                                   batch_size=BATCH_SIZE)\n",
        "\n",
        "# Create train dataloader *without* data augmentation\n",
        "train_dataloader_20_percent_without_aug, test_dataloader_20_percent, class_names = create_dataloaders(train_dir=train_20_percent_dir,\n",
        "                                                                                                   test_dir=test_20_percent_dir,\n",
        "                                                                                                   train_transform=train_transform_data_aug,\n",
        "                                                                                                   test_transform=no_data_aug_transform,\n",
        "                                                                                                   batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "C7-sJ6HNnpKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a function for viewing different images"
      ],
      "metadata": {
        "id": "hBDYSwurnpH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visulize different samples from both dataloaders (aug and no aug)\n",
        "def view_dataloader_images(dataloader, n=10):\n",
        "    if n > 10:\n",
        "        print(f\"Having n higher than 10 will create messy plots, lowering to 10.\")\n",
        "        n = 10\n",
        "    imgs, labels = next(iter(dataloader))\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    for i in range(n):\n",
        "        # Min max scale the image for display purposes\n",
        "        targ_image = imgs[i]\n",
        "        sample_min, sample_max = targ_image.min(), targ_image.max()\n",
        "        sample_scaled = (targ_image - sample_min)/(sample_max - sample_min)\n",
        "\n",
        "        # Plot images with appropriate axes information\n",
        "        plt.subplot(1, 10, i+1)\n",
        "        plt.imshow(sample_scaled.permute(1, 2, 0)) # resize for Matplotlib requirements\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(False)"
      ],
      "metadata": {
        "id": "i0EuycZonpE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out samples with data augmentation\n",
        "view_dataloader_images(train_dataloader_20_percent_with_aug)"
      ],
      "metadata": {
        "id": "36jfqUk5npBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkout samples without data augmentation\n",
        "view_dataloader_images(train_dataloader_20_percent_without_aug)"
      ],
      "metadata": {
        "id": "r9ajQRNgrBEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Augmentation v no augmentation"
      ],
      "metadata": {
        "id": "40lAMvt9rBBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup number of epochs\n",
        "num_epochs = [5, 10]\n",
        "\n",
        "# Create dataloaders dictionary for various dataloaders\n",
        "train_dataloaders = {\"data_20_percent_with_aug\": train_dataloader_20_percent_with_aug,\n",
        "                     \"data_20_percent_without_aug\": train_dataloader_20_percent_without_aug}\n",
        "\n",
        "# Create model\n",
        "models = [\"effnetv2_s\"]"
      ],
      "metadata": {
        "id": "qZKSdlNhrA-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from going_modular.utils import save_model\n",
        "\n",
        "# 1. Set the random seeds\n",
        "set_seeds(seed=42)\n",
        "\n",
        "# 2. Keep track of experiment numbers\n",
        "experiment_number = 0\n",
        "\n",
        "# 3. Loop through each DataLoader\n",
        "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
        "\n",
        "    # 4. Loop through each number of epochs\n",
        "    for epochs in num_epochs:\n",
        "\n",
        "        # 5. Loop through each model name and create a new model based on the name\n",
        "        for model_name in models:\n",
        "\n",
        "            # 6. Create information print outs\n",
        "            experiment_number += 1\n",
        "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
        "            print(f\"[INFO] Model: {model_name}\")\n",
        "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
        "            print(f\"[INFO] Number of epochs: {epochs}\")\n",
        "\n",
        "            # 7. Select the model\n",
        "            if model_name == \"effnetb2\":\n",
        "              model = create_effnetb2()\n",
        "            else:\n",
        "              model = create_effnetv2_s()\n",
        "\n",
        "            # 8. Create a new loss and optimizer for every model\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "            # 9. Train target model with target dataloaders and track experiments\n",
        "            train(model=model,\n",
        "                  train_dataloader=train_dataloader,\n",
        "                  test_dataloader=test_dataloader_20_percent, ### New, use test_dataloader_20_percent\n",
        "                  optimizer=optimizer,\n",
        "                  loss_fn=loss_fn,\n",
        "                  epochs=epochs,\n",
        "                  device=device,\n",
        "                  writer=create_writer(experiment_name=dataloader_name,\n",
        "                                       model_name=model_name,\n",
        "                                       extra=f\"{epochs}_epochs\"))\n",
        "\n",
        "            # 10. Save the model to file so we can get back the best model\n",
        "            save_filepath = f\"07_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
        "            save_model(model=model,\n",
        "                       target_dir=\"models\",\n",
        "                       model_name=save_filepath)\n",
        "            print(\"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "jWbfflgArA33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "ryhq4ry6rrep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Looks like EffNetV2_S without data augmentation performed the best on average for test loss and test accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "qEkNOYUrrwZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3. Scale up the dataset to turn FoodVision Mini into FoodVision Big using the entire Food101 dataset from `torchvision.models`"
      ],
      "metadata": {
        "id": "6R_35nVTrrJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get Food 101 Dataset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "#create transform to normalize inline w/ ImageNet\n",
        "normalize=transforms.Normalize(mean=[0.485, 0.456, 0.406], # values per colour channel [red, green, blue]\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "simple_transform = transforms.Compose([\n",
        "                                       transforms.Resize((224, 224)),\n",
        "                                       transforms.ToTensor(), # get image values between 0 & 1\n",
        "                                       normalize\n",
        "])\n",
        "\n",
        "train_data=torchvision.datasets.Food101(root=\"data\",\n",
        "                                      split=\"train\",\n",
        "                                      transform=simple_transform,\n",
        "                                      download=True)\n",
        "\n",
        "test_data=torchvision.datasets.Food101(root=\"data\",\n",
        "                                      split=\"test\",\n",
        "                                      transform=simple_transform,\n",
        "                                      download=True)\n",
        "\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "d_5DuaCmBvUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Food101 DataLoaders"
      ],
      "metadata": {
        "id": "gKCd4bASLtB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "import os\n",
        "BATCH_SIZE = 512 # use a big batch size to get through all the images (100,000+ in Food101)\n",
        "\n",
        "train_dataloader_big = torch.utils.data.DataLoader(train_data,\n",
        "                                                   shuffle=True,\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   num_workers=os.cpu_count(),\n",
        "                                                   pin_memory=True) # avoid copies of the data into and out of memory, where possible (for speed ups)\n",
        "\n",
        "test_dataloader_big = torch.utils.data.DataLoader(test_data,\n",
        "                                                  shuffle=False,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  num_workers=os.cpu_count(),\n",
        "                                                  pin_memory=True)"
      ],
      "metadata": {
        "id": "C-ZNU5FULtSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create FoodVision Big model and train it"
      ],
      "metadata": {
        "id": "UrXCVDENKuGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnetv2_s_weights=torchvision.models.EfficientNet_V2_S_Weights.DEFAULT #DEFAULT=\"best available weights\"\n",
        "foodvision_big_model=torchvision.models.efficientnet_v2_s(weights=effnetv2_s_weights)\n",
        "\n",
        "#freeze base layers\n",
        "for param in foodvision_big_model.features.parameters():\n",
        "  param.requires_grad=False\n",
        "\n",
        "#change the classifier to have 3 out classes\n",
        "foodvision_big_model.classifier=nn.Sequential(nn.Dropout(p=0.2),\n",
        "                                              nn.Linear(in_features=1280,\n",
        "                                                        out_features=101)).to(device) #101 outputs for food101\n",
        "summary(model=foodvision_big_model,\n",
        "         input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "6BzJsG3gr8KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foodvision_big_results = train(model=foodvision_big_model,\n",
        "                               train_dataloader=train_dataloader_big,\n",
        "                               test_dataloader=test_dataloader_big,\n",
        "                               optimizer=torch.optim.Adam(params=foodvision_big_model.parameters(), lr=0.001),\n",
        "                               loss_fn=torch.nn.CrossEntropyLoss(),\n",
        "                               epochs=5,\n",
        "                               device=device,\n",
        "                               writer=create_writer(experiment_name=\"food101_all_data\",\n",
        "                                                    model_name=\"foodvision_big\",\n",
        "                                                    extra=f\"{epochs}_epochs\"))"
      ],
      "metadata": {
        "id": "y2lrZxtYKxq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "OK_mvnMeKxna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7KKHHFMtKxjP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}